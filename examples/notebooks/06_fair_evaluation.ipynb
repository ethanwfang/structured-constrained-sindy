{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC-SINDy Fair Evaluation (No Oracle)\n",
    "\n",
    "This notebook demonstrates **fair evaluation** of Structure-Constrained SINDy using **learned** structure predictions instead of oracle (ground truth) access.\n",
    "\n",
    "## Key Differences from Oracle Evaluation\n",
    "\n",
    "| Aspect | Oracle (Unfair) | Learned (Fair) |\n",
    "|--------|-----------------|----------------|\n",
    "| Structure source | Ground truth | Trained network |\n",
    "| Train/test split | None | System-level split |\n",
    "| Results | Overly optimistic | Realistic |\n",
    "| Publishable | No | Yes |\n",
    "\n",
    "**Run this notebook in Google Colab to evaluate SC-SINDy properly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SC-SINDy (uncomment for Colab)\n",
    "# !pip install git+https://github.com/yourusername/structure-constrained-sindy.git[torch,viz] -q\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Type\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC-SINDy imports\n",
    "from sc_sindy import (\n",
    "    sindy_stls,\n",
    "    sindy_structure_constrained,\n",
    "    build_library_2d,\n",
    "    compute_derivatives_finite_diff,\n",
    "    compute_structure_metrics,\n",
    "    format_equation,\n",
    ")\n",
    "\n",
    "# Systems\n",
    "from sc_sindy.systems import (\n",
    "    VanDerPol, DuffingOscillator, DampedHarmonicOscillator,\n",
    "    LotkaVolterra, SelkovGlycolysis, CoupledBrusselator,\n",
    "    DynamicalSystem,\n",
    ")\n",
    "\n",
    "# Network components\n",
    "from sc_sindy.network import (\n",
    "    StructureNetwork,\n",
    "    StructurePredictor,\n",
    "    train_structure_network,\n",
    "    train_structure_network_with_split,\n",
    "    extract_trajectory_features,\n",
    ")\n",
    "\n",
    "# Evaluation framework\n",
    "from sc_sindy.evaluation import (\n",
    "    get_split,\n",
    "    print_split_info,\n",
    "    SCSINDyEvaluator,\n",
    "    TRAIN_SYSTEMS_2D,\n",
    "    TEST_SYSTEMS_2D,\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split\n",
    "\n",
    "The key to fair evaluation is splitting at the **system level**, not the trajectory level.\n",
    "\n",
    "- **Train systems**: Used to train the structure network\n",
    "- **Test systems**: Held out completely - never seen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the train/test split\n",
    "print_split_info()\n",
    "\n",
    "# Get the 2D split\n",
    "train_systems, test_systems = get_split(dimension=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"We will:\")\n",
    "print(f\"  1. Train network on: {[s.__name__ for s in train_systems]}\")\n",
    "print(f\"  2. Evaluate on: {[s.__name__ for s in test_systems]}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Training Data\n",
    "\n",
    "Generate trajectories ONLY from training systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(\n",
    "    system_classes: List[Type[DynamicalSystem]],\n",
    "    n_trajectories: int = 100,\n",
    "    noise_levels: List[float] = None,\n",
    "):\n",
    "    \"\"\"Generate training data from system classes.\"\"\"\n",
    "    if noise_levels is None:\n",
    "        noise_levels = [0.0, 0.05, 0.10]\n",
    "    \n",
    "    # Get library term names\n",
    "    dummy_x = np.random.randn(10, 2)\n",
    "    _, term_names = build_library_2d(dummy_x)\n",
    "    \n",
    "    t = np.linspace(0, 50, 5000)\n",
    "    dt = t[1] - t[0]\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for SystemClass in system_classes:\n",
    "        system = SystemClass()\n",
    "        print(f\"  Generating data for {system.name}...\")\n",
    "        \n",
    "        # Get true structure for this system\n",
    "        true_structure = system.get_true_structure(term_names)\n",
    "        structure_flat = true_structure.flatten().astype(float)\n",
    "        \n",
    "        n_per_system = n_trajectories // len(system_classes)\n",
    "        success_count = 0\n",
    "        \n",
    "        for _ in range(n_per_system * 2):  # Try extra to handle failures\n",
    "            if success_count >= n_per_system:\n",
    "                break\n",
    "                \n",
    "            x0 = np.random.randn(2) * 2\n",
    "            noise = np.random.choice(noise_levels)\n",
    "            \n",
    "            try:\n",
    "                x = system.generate_trajectory(x0, t, noise_level=noise)\n",
    "                \n",
    "                if np.any(np.isnan(x)) or np.any(np.isinf(x)):\n",
    "                    continue\n",
    "                \n",
    "                # Trim edges\n",
    "                x_trim = x[100:-100]\n",
    "                \n",
    "                # Extract features\n",
    "                features = extract_trajectory_features(x_trim, dt)\n",
    "                \n",
    "                if np.any(np.isnan(features)) or np.any(np.isinf(features)):\n",
    "                    continue\n",
    "                \n",
    "                all_data.append((features, structure_flat))\n",
    "                success_count += 1\n",
    "                \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        print(f\"    Generated {success_count} trajectories\")\n",
    "    \n",
    "    return all_data, term_names\n",
    "\n",
    "# Generate training data from TRAIN systems only\n",
    "print(\"Generating training data...\")\n",
    "print(\"(This uses ONLY training systems - test systems are held out)\\n\")\n",
    "\n",
    "train_data, term_names = generate_training_data(\n",
    "    TRAIN_SYSTEMS_2D,\n",
    "    n_trajectories=200,\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal training samples: {len(train_data)}\")\n",
    "print(f\"Feature dimension: {train_data[0][0].shape[0]}\")\n",
    "print(f\"Output dimension: {train_data[0][1].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Structure Network\n",
    "\n",
    "Train the network to predict equation structure from trajectory features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalization statistics\n",
    "all_features = np.array([f for f, _ in train_data])\n",
    "feature_mean = np.mean(all_features, axis=0)\n",
    "feature_std = np.std(all_features, axis=0)\n",
    "feature_std = np.where(feature_std < 1e-10, 1.0, feature_std)\n",
    "\n",
    "# Normalize training data\n",
    "normalized_data = [\n",
    "    ((features - feature_mean) / feature_std, labels)\n",
    "    for features, labels in train_data\n",
    "]\n",
    "\n",
    "print(\"Training structure network...\")\n",
    "print(\"(This learns to predict structure WITHOUT seeing test systems)\\n\")\n",
    "\n",
    "model, history = train_structure_network(\n",
    "    normalized_data,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    lr=0.001,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Final validation loss: {history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train', alpha=0.8)\n",
    "plt.plot(history['val_loss'], label='Validation', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_loss'], 'orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss (zoom)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor with normalization\n",
    "n_vars = 2\n",
    "n_terms = len(term_names)\n",
    "\n",
    "predictor = StructurePredictor(\n",
    "    model=model,\n",
    "    n_vars=n_vars,\n",
    "    n_terms=n_terms,\n",
    "    feature_mean=feature_mean,\n",
    "    feature_std=feature_std,\n",
    ")\n",
    "\n",
    "print(\"StructurePredictor created!\")\n",
    "print(f\"  n_vars: {n_vars}\")\n",
    "print(f\"  n_terms: {n_terms}\")\n",
    "print(f\"  term_names: {term_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Test Systems\n",
    "\n",
    "Now we evaluate SC-SINDy using the **learned** network predictions on systems that were **never seen during training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fair(\n",
    "    test_system_classes: List[Type[DynamicalSystem]],\n",
    "    predictor: StructurePredictor,\n",
    "    term_names: List[str],\n",
    "    n_trials: int = 20,\n",
    "    noise_levels: List[float] = None,\n",
    "):\n",
    "    \"\"\"Evaluate SC-SINDy with LEARNED predictions on test systems.\"\"\"\n",
    "    if noise_levels is None:\n",
    "        noise_levels = [0.0, 0.05, 0.10]\n",
    "    \n",
    "    t = np.linspace(0, 50, 5000)\n",
    "    dt = t[1] - t[0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for SystemClass in test_system_classes:\n",
    "        system = SystemClass()\n",
    "        print(f\"\\nEvaluating on {system.name} (TEST SYSTEM - never seen in training)\")\n",
    "        \n",
    "        true_xi = system.get_true_coefficients(term_names)\n",
    "        true_structure = np.abs(true_xi) > 1e-6\n",
    "        \n",
    "        for noise in noise_levels:\n",
    "            std_f1s, sc_f1s, net_f1s = [], [], []\n",
    "            \n",
    "            for _ in range(n_trials):\n",
    "                x0 = np.random.randn(2) * 2\n",
    "                \n",
    "                try:\n",
    "                    x = system.generate_trajectory(x0, t, noise_level=noise)\n",
    "                    if np.any(np.isnan(x)) or np.any(np.isinf(x)):\n",
    "                        continue\n",
    "                    \n",
    "                    x_trim = x[100:-100]\n",
    "                    x_dot = compute_derivatives_finite_diff(x_trim, dt)\n",
    "                    Theta, _ = build_library_2d(x_trim)\n",
    "                    \n",
    "                    # Standard SINDy\n",
    "                    xi_std, _ = sindy_stls(Theta, x_dot, threshold=0.1)\n",
    "                    \n",
    "                    # SC-SINDy with LEARNED predictions (NOT oracle!)\n",
    "                    network_probs = predictor.predict_from_trajectory(x_trim, dt)\n",
    "                    xi_sc, _ = sindy_structure_constrained(\n",
    "                        Theta, x_dot, network_probs, structure_threshold=0.3\n",
    "                    )\n",
    "                    \n",
    "                    # Metrics\n",
    "                    metrics_std = compute_structure_metrics(xi_std, true_xi)\n",
    "                    metrics_sc = compute_structure_metrics(xi_sc, true_xi)\n",
    "                    \n",
    "                    # Network prediction quality\n",
    "                    pred_structure = network_probs > 0.5\n",
    "                    net_metrics = compute_structure_metrics(\n",
    "                        pred_structure.astype(float), \n",
    "                        true_structure.astype(float)\n",
    "                    )\n",
    "                    \n",
    "                    std_f1s.append(metrics_std['f1'])\n",
    "                    sc_f1s.append(metrics_sc['f1'])\n",
    "                    net_f1s.append(net_metrics['f1'])\n",
    "                    \n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            if std_f1s:\n",
    "                results.append({\n",
    "                    'system': system.name,\n",
    "                    'noise': noise,\n",
    "                    'std_f1_mean': np.mean(std_f1s),\n",
    "                    'std_f1_std': np.std(std_f1s),\n",
    "                    'sc_f1_mean': np.mean(sc_f1s),\n",
    "                    'sc_f1_std': np.std(sc_f1s),\n",
    "                    'net_f1_mean': np.mean(net_f1s),\n",
    "                    'improvement': np.mean(sc_f1s) - np.mean(std_f1s),\n",
    "                    'n_trials': len(std_f1s),\n",
    "                })\n",
    "                \n",
    "                print(f\"  Noise {noise:.2f}: Std F1={np.mean(std_f1s):.3f}, \"\n",
    "                      f\"SC F1={np.mean(sc_f1s):.3f}, \"\n",
    "                      f\"Net F1={np.mean(net_f1s):.3f}, \"\n",
    "                      f\"Improve={np.mean(sc_f1s)-np.mean(std_f1s):+.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run fair evaluation\n",
    "print(\"=\"*60)\n",
    "print(\"FAIR EVALUATION (No Oracle Access)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTest systems have NEVER been seen during training!\")\n",
    "\n",
    "results = evaluate_fair(\n",
    "    TEST_SYSTEMS_2D,\n",
    "    predictor,\n",
    "    term_names,\n",
    "    n_trials=20,\n",
    "    noise_levels=[0.0, 0.05, 0.10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FAIR EVALUATION RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'System':<25} {'Noise':<8} {'Std F1':<12} {'SC F1':<12} {'Net F1':<10} {'Improve':<10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r['system']:<25} {r['noise']:<8.2f} \"\n",
    "          f\"{r['std_f1_mean']:.3f}+/-{r['std_f1_std']:.2f}  \"\n",
    "          f\"{r['sc_f1_mean']:.3f}+/-{r['sc_f1_std']:.2f}  \"\n",
    "          f\"{r['net_f1_mean']:.3f}      \"\n",
    "          f\"{r['improvement']:+.3f}\")\n",
    "\n",
    "# Overall statistics\n",
    "all_std = [r['std_f1_mean'] for r in results]\n",
    "all_sc = [r['sc_f1_mean'] for r in results]\n",
    "all_improve = [r['improvement'] for r in results]\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"{'OVERALL':<25} {'---':<8} \"\n",
    "      f\"{np.mean(all_std):.3f}          \"\n",
    "      f\"{np.mean(all_sc):.3f}          \"\n",
    "      f\"{'---':<10} \"\n",
    "      f\"{np.mean(all_improve):+.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT:\")\n",
    "if np.mean(all_improve) > 0:\n",
    "    print(f\"SC-SINDy improves F1 by {np.mean(all_improve):.3f} on average on UNSEEN systems!\")\n",
    "else:\n",
    "    print(f\"SC-SINDy shows {np.mean(all_improve):.3f} change - network may need more training data.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart by system\n",
    "systems = list(set(r['system'] for r in results))\n",
    "x = np.arange(len(systems))\n",
    "width = 0.35\n",
    "\n",
    "std_means = [np.mean([r['std_f1_mean'] for r in results if r['system'] == s]) for s in systems]\n",
    "sc_means = [np.mean([r['sc_f1_mean'] for r in results if r['system'] == s]) for s in systems]\n",
    "\n",
    "axes[0].bar(x - width/2, std_means, width, label='Standard SINDy', color='steelblue', alpha=0.8)\n",
    "axes[0].bar(x + width/2, sc_means, width, label='SC-SINDy (Learned)', color='darkorange', alpha=0.8)\n",
    "axes[0].set_xlabel('Test System')\n",
    "axes[0].set_ylabel('F1 Score')\n",
    "axes[0].set_title('Performance on Held-Out Test Systems')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(systems, rotation=15)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1.1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Improvement by noise level\n",
    "noise_levels = sorted(set(r['noise'] for r in results))\n",
    "improvements = [np.mean([r['improvement'] for r in results if r['noise'] == n]) for n in noise_levels]\n",
    "\n",
    "colors = ['green' if i > 0 else 'red' for i in improvements]\n",
    "axes[1].bar(range(len(noise_levels)), improvements, color=colors, alpha=0.8)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].set_xlabel('Noise Level')\n",
    "axes[1].set_ylabel('F1 Improvement (SC - Standard)')\n",
    "axes[1].set_title('SC-SINDy Improvement by Noise Level')\n",
    "axes[1].set_xticks(range(len(noise_levels)))\n",
    "axes[1].set_xticklabels([f'{n:.0%}' for n in noise_levels])\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Network Prediction Analysis\n",
    "\n",
    "Let's analyze what the network learned and how well it predicts structure on test systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze network predictions on test systems\n",
    "print(\"Network Prediction Analysis on Test Systems\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "t = np.linspace(0, 50, 5000)\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "for SystemClass in TEST_SYSTEMS_2D:\n",
    "    system = SystemClass()\n",
    "    true_structure = system.get_true_structure(term_names)\n",
    "    \n",
    "    # Generate a test trajectory\n",
    "    x0 = np.array([1.0, 0.0])\n",
    "    x = system.generate_trajectory(x0, t)\n",
    "    x_trim = x[100:-100]\n",
    "    \n",
    "    # Get network prediction\n",
    "    probs = predictor.predict_from_trajectory(x_trim, dt)\n",
    "    \n",
    "    print(f\"\\n{system.name}:\")\n",
    "    print(f\"  True structure (eq1): {[term_names[i] for i in range(len(term_names)) if true_structure[0, i]]}\")\n",
    "    print(f\"  True structure (eq2): {[term_names[i] for i in range(len(term_names)) if true_structure[1, i]]}\")\n",
    "    print(f\"  Predicted probs (eq1): {probs[0].round(3)}\")\n",
    "    print(f\"  Predicted probs (eq2): {probs[1].round(3)}\")\n",
    "    \n",
    "    # Highlight predictions for true terms\n",
    "    print(f\"  Probs for TRUE terms (eq1): {probs[0][true_structure[0]].round(3)}\")\n",
    "    print(f\"  Probs for TRUE terms (eq2): {probs[1][true_structure[1]].round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison: Oracle vs Learned\n",
    "\n",
    "Let's compare the results with oracle access (cheating) vs learned predictions (fair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare oracle vs learned on one test system\n",
    "system = TEST_SYSTEMS_2D[0]()\n",
    "print(f\"Comparing Oracle vs Learned on {system.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "true_xi = system.get_true_coefficients(term_names)\n",
    "true_structure = np.abs(true_xi) > 1e-6\n",
    "\n",
    "oracle_f1s, learned_f1s, std_f1s = [], [], []\n",
    "\n",
    "for _ in range(30):\n",
    "    x0 = np.random.randn(2) * 2\n",
    "    x = system.generate_trajectory(x0, t, noise_level=0.05)\n",
    "    \n",
    "    if np.any(np.isnan(x)):\n",
    "        continue\n",
    "    \n",
    "    x_trim = x[100:-100]\n",
    "    x_dot = compute_derivatives_finite_diff(x_trim, dt)\n",
    "    Theta, _ = build_library_2d(x_trim)\n",
    "    \n",
    "    # Standard SINDy\n",
    "    xi_std, _ = sindy_stls(Theta, x_dot, threshold=0.1)\n",
    "    \n",
    "    # Oracle (CHEATING - uses ground truth)\n",
    "    oracle_probs = true_structure.astype(float) * 0.9 + 0.05\n",
    "    xi_oracle, _ = sindy_structure_constrained(Theta, x_dot, oracle_probs, structure_threshold=0.3)\n",
    "    \n",
    "    # Learned (FAIR - uses network prediction)\n",
    "    learned_probs = predictor.predict_from_trajectory(x_trim, dt)\n",
    "    xi_learned, _ = sindy_structure_constrained(Theta, x_dot, learned_probs, structure_threshold=0.3)\n",
    "    \n",
    "    std_f1s.append(compute_structure_metrics(xi_std, true_xi)['f1'])\n",
    "    oracle_f1s.append(compute_structure_metrics(xi_oracle, true_xi)['f1'])\n",
    "    learned_f1s.append(compute_structure_metrics(xi_learned, true_xi)['f1'])\n",
    "\n",
    "print(f\"\\nResults (30 trials, 5% noise):\")\n",
    "print(f\"  Standard SINDy:     F1 = {np.mean(std_f1s):.3f} +/- {np.std(std_f1s):.3f}\")\n",
    "print(f\"  SC-SINDy (Oracle):  F1 = {np.mean(oracle_f1s):.3f} +/- {np.std(oracle_f1s):.3f}  <- CHEATING!\")\n",
    "print(f\"  SC-SINDy (Learned): F1 = {np.mean(learned_f1s):.3f} +/- {np.std(learned_f1s):.3f}  <- FAIR\")\n",
    "print(f\"\\nOracle improvement: {np.mean(oracle_f1s) - np.mean(std_f1s):+.3f} (not publishable)\")\n",
    "print(f\"Learned improvement: {np.mean(learned_f1s) - np.mean(std_f1s):+.3f} (publishable!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated **fair evaluation** of SC-SINDy:\n",
    "\n",
    "1. **Train/test split at system level** - Test systems never seen during training\n",
    "2. **Learned structure predictions** - Not oracle/ground truth\n",
    "3. **Realistic performance** - Results are publishable\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Oracle testing (using ground truth) gives overly optimistic results\n",
    "- Fair evaluation with learned predictions shows realistic improvement\n",
    "- The network must generalize to unseen systems to be useful\n",
    "- More diverse training data = better generalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
